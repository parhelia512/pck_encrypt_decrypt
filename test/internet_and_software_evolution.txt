The evolution of software and information technology to Web 3.0

An attempt to briefly walk-though how software, computing, and technology evolves, and how the Internet comes to the status of Web 3.0 now in 2022

Philip Kwan
Mar 4

My career of software engineering began in 2004, as I worked for a multinational technology company, Cisco Systems. From then on, or even years before that, software, technology, and the Internet evolved at rapid speed.

I would like to give a brief overview about what these changes are, focusing on my perspective on how they change and become what we are experiencing nowadays.

My focus is on the Internet technology and applications that are used by the general and ordinary people, several key concepts and high level architecture, and how they evolved over the years, giving to the terms of SaaS, API, blockchain, and Web 3.0.

The history of computing went a long way back, in which I will try to start from the 1990s.

Standalone software on PCs in the 1990s
I began to learn to use a personal computer (PC) when I was a student in the 1990s, gradually exposing myself to the Internet and the World Wide Web.

The Internet was not as mature as what we see today, using a computer back in the 90’s mostly means turning on my PC, opening Microsoft Word, and writing up my homework in a document so that I could print it out and submit it in person.
Those were the days of standalone software, meaning software application that runs by itself, with none or very minimal need to connect and interact with the Internet.


Running standalone applications like Microsoft Office in 1997
Web pages and the client-server model of the Internet
Then I started to dial up and connected to the Internet using a modem and via my home phone line.
I browsed World Wide Web (www) pages that were pretty static.


The Lego web page in 1997
A web browser (i.e. Internet Explorer) is a client application, it makes connection to the Internet, and with the URL (Uniform Resource Locator, a.k.a the address) you provided, it goes to a server to fetch a web page and display to you.
This client-server model of computing is a fundamental architecture when applications on the client side ask for data from the server side, and the server applications “serve” the clients.


A client (web browser) request for a web page, the server “serves” the page back to the client.
Key concepts in the Web 1.0 era
From today’s perspective, we reflected back with the term “Web 1.0” to the period of time when Internet started, up to the early 2000s.
Web 1.0 defines the period when the Internet contents were quite static and centralized, users like myself are merely asking for content and then some servers serve them to us.

As I went to college studying Electrical Engineering and Computer Science in 2000, I was able to gain more understanding on programming, computing, Internet and technology in general.

After my undergraduate studies, I started my career as a software engineer, developing applications that are run and used as part of the Internet.
I was then exposed more to these key concepts and knowledges when developing such applications.

-request-response model

-how application logic is distributed

-where data is persisted

The concepts remains and evolves from the Web 1.0 time to the present.


Request-response

The concept of request and response is very similar to the client-server model, where a client usually “requests” something from a server, and the server “responds” to the client’s request.

But they are somewhat different. A client can make a request to another client too. For example, typical voice application (i.e. Skype) where user A calls user B. The request initiated by user A is a client application, it might route to a server, but eventually it has to request user B’s client application, causing the phone to ring.

In sum, the client-server model is used to describe the physical separation of computers, and in general, an end user like you and I, interact from a client side using computer or electronic devices, like a smart phone. On the other hand, the request-response model is used to describe an individual or specific transaction, where it always starts with a request from some system to another, and a response answers the request.

Voice-Over-IP (VOIP) application is an example where a request initiated from a client, and finally reaches another client. Such a request might route through several intermediate servers.
How application logic is distributed
Software applications are built using programming languages.
The act of developing a software application is called software development, programming, or coding.
Depending on the complexity and size of a program, the amount of code can be big or small, from thousands of lines of code to hundreds of thousands or even millions lines of code.
Examples of big and complex software applications that we often use are:

-Microsoft Word—an application that helps you to write documents

-Minecraft—a desktop game that many people play on PC and consoles

-Candy Crush—a mobile game that many people play on their smart phones

-Gmail—an application that runs on a browser and lets you receive and send emails

The technical term to describe the way these applications behave is called application logic, and application logic distributes among clients and servers.

Like a civil architect who designs the layout and plan for a building, there is a role of a software architect that design the layout, structure, and distribution of application logic for a software application. To give a quick comparison, let me use Candy Crush and Gmail as examples.

Candy Crush can be considered to have quite a lot of application logic on the client (i.e. mobile phone) side. That is, there is not necessary too many requests to be made to a server in order for a user to play the game, as the game runs entirely on the phone.
It is only when a game is finished, the game results will need to be communicated back to the game server, in order to calculate scores and give out rewards to the player.

Gmail has relatively less application logic on the client (i.e. browser) side, as compared to Candy Crush. When a user opens Gmail from a browser, the browser makes several requests to fetch email mailbox data of the user, then displays on the browser. If a user clicks on a specific email title to see the details, the browser will make some more requests to the Gmail server to retrieve it. In other words, the browser doesn’t store a lot of data or logic on the client side for Gmail.

Where data is persisted
As we rely more and more on computer and technology, more data are being generated and need to be stored. We use the term “persistence” meaning to store data, permanently, from interactions between users, computers and systems.

A common place to persist data is the database. A database is also a software application that serves the purpose of persisting data, usually to the hard disk. Most applications have connections to databases, and they are usually connected from a server in a client-server model. In other words, a client application doesn’t store data directly to the database, but instead make requests to the server to handle it. The server application has application logic to determine how and where the database should store the data.

Together, a typical interaction between an end user, the application and service, and finally where information are persisted, is express by a model called a 3-Tier Application Architecture.


Given an example, I log in to my eBanking application from my web browser (client), the application connects to an application server hosted at the bank’s datacenter. I did some transactions such as paying my online bills, transferring money from one account to another. All my transactions are persisted in the bank’s database. I then log out of my eBanking application, rest assured that my transactions are finalized by the bank’s system and I can log in another day to confirm they have already happened.

The above concepts that I briefly talked about: client-server, request-response, application logic distribution, and data persistent, they are all fundamental concepts that when computer and information technology advances to the next phase, they are still core to the understanding, design and architecture of new inventions.

